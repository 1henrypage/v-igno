{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Replication of Darcy Flow Continuous",
   "id": "8f111b1b3e778f1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from src.solver.config import OptimizerConfig, SchedulerConfig, LossWeights\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../..\")))\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.solver_utils import get_model\n",
    "\n",
    "\n",
    "\n",
    "from src.solver.base import ProblemInstance, Solver\n",
    "from src.utils.misc_utils import np2tensor, setup_seed, get_default_device\n",
    "from src.utils.RBFInterpolatorMesh import RBFInterpolator\n",
    "from src.utils.PlotFigure import Plot\n",
    "from src.components.encoder import EncoderCNNet2dTanh\n",
    "\n",
    "print(f'Current Directory {os.getcwd()}')\n",
    "\n",
    "setup_seed(seed=10086)\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float32\n",
    "\n",
    "######################################\n",
    "# Load training data\n",
    "######################################\n",
    "\n",
    "\n",
    "def get_data(data, dtype):\n",
    "    a = np2tensor(np.array(data[\"coeff\"]).T, dtype)\n",
    "    u = np2tensor(np.array(data[\"sol\"]).T, dtype)\n",
    "    #\n",
    "    X, Y = np.array(data['X']).T, np.array(data['Y']).T\n",
    "    mesh = np2tensor(np.vstack([X.ravel(), Y.ravel()]).T, dtype)\n",
    "    gridx = mesh.reshape(-1, 2)\n",
    "    #\n",
    "    ndata = a.shape[0]\n",
    "    a = a.reshape(ndata, -1, 1)\n",
    "    x = gridx.repeat((ndata, 1, 1))\n",
    "    u = u.reshape(ndata, -1, 1)\n",
    "\n",
    "    return a, u, x, gridx\n",
    "#\n",
    "data_train = h5py.File('../../data/darcy_continuous/smh_train.mat', 'r')\n",
    "data_test = h5py.File('../../data/darcy_continuous/smh_test_in.mat', 'r')\n",
    "a_train, u_train, x_train, gridx_train = get_data(data_train, dtype)\n",
    "a_test, u_test, x_test, gridx_test = get_data(data_test, dtype)\n",
    "#\n",
    "print('The shape of x_train:', x_train.shape)\n",
    "print('The shape of a_train:', a_train.shape)\n",
    "print('The shape of gridx_train:', gridx_train.shape)\n",
    "print('**********************************')\n",
    "print('The shape of x_test:', x_test.shape)\n",
    "print('The shape of a_test:', a_test.shape)\n",
    "print('The shape of u_test:', u_test.shape)\n",
    "print('The shape of gridx_test:', gridx_test.shape)\n",
    "########################################\n",
    "Plot.show_2d_list(\n",
    "    [gridx_train.cpu().numpy()]*3 + [gridx_test.cpu().numpy()],\n",
    "    [a_train[0].cpu().numpy(), u_train[0].cpu().numpy(),\n",
    "     a_test[0].cpu().numpy(), u_test[0].cpu().numpy()],\n",
    "    ['a_train', 'u_train', 'a_test', 'u_test'],\n",
    "    lb=0.\n",
    ")\n"
   ],
   "id": "587f65375ed51057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate points and integral grid",
   "id": "37f3e8aec57fb1c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import grad, Variable\n",
    "from src.utils.TestFun_ParticleWNN import TestFun_ParticleWNN\n",
    "from src.utils.GenPoints import Point2D\n",
    "\n",
    "genPoint = Point2D(x_lb=[0., 0.], x_ub=[1., 1.], dataType=dtype)\n",
    "\n",
    "###############################\n",
    "# The test function\n",
    "###############################\n",
    "int_grid, v, dv_dr = TestFun_ParticleWNN(\n",
    "    fun_type='Wendland', dim=2, n_mesh_or_grid=9, dataType=dtype).get_testFun()\n",
    "print('int_grid shape:', int_grid.shape, 'v shape:', v.shape)\n",
    "\n"
   ],
   "id": "70a5bc48a4d26374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mollifier",
   "id": "eebb4294950c1595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:05:26.973857441Z",
     "start_time": "2025-12-14T14:05:26.964778753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Mollifier:\n",
    "\n",
    "    def __call__(self, u, x):\n",
    "        u = u * torch.sin(np.pi * x[...,0])*torch.sin(np.pi * x[...,1])\n",
    "        return u.unsqueeze(-1)\n"
   ],
   "id": "5eb43b6066f02566",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models",
   "id": "4f87f5484bed7777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net_type = 'MultiONetBatch'\n",
    "beta_size = 128\n",
    "hidden_size = 100\n",
    "# Copied from DGNO\n",
    "fun_a = RBFInterpolator(\n",
    "    x_mesh=gridx_train,\n",
    "    kernel='gaussian',\n",
    "    eps=25.,\n",
    "    smoothing=0.,\n",
    "    degree=6,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "############ Encoder Architecture ########\n",
    "conv_arch = [1,64,64,64]\n",
    "fc_arch = [64*2*2, 128, 128, beta_size]\n",
    "model_enc = EncoderCNNet2dTanh(\n",
    "    conv_arch=conv_arch,\n",
    "    fc_arch=fc_arch,\n",
    "    activation_conv='SiLU',\n",
    "    activation_fc='SiLU',\n",
    "    nx_size=29,\n",
    "    ny_size=29,\n",
    "    kernel_size=(3,3),\n",
    "    stride=2,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "############ Decoder Architecture\n",
    "trunk_layers, branch_layers = [hidden_size] * 6, [hidden_size] * 6\n",
    "#\n",
    "model_a = get_model(\n",
    "    x_in_size=2,\n",
    "    beta_in_size=beta_size,\n",
    "    trunk_layers=trunk_layers,\n",
    "    branch_layers=branch_layers,\n",
    "    activation_trunk='Tanh_Sin',\n",
    "    activation_branch='Tanh_Sin',\n",
    "    net_type=net_type,\n",
    "    sum_layers=5\n",
    ")\n",
    "\n",
    "\n",
    "model_u = get_model(\n",
    "    x_in_size=2,\n",
    "    beta_in_size=beta_size,\n",
    "    trunk_layers=trunk_layers,\n",
    "    branch_layers=branch_layers,\n",
    "    activation_trunk='Tanh_Sin',\n",
    "    activation_branch='Tanh_Sin',\n",
    "    net_type=net_type,\n",
    "    sum_layers=5\n",
    ")\n",
    "####################\n",
    "total_trainable_params_enc = sum(p.numel() for p in model_enc.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params_enc:,} training parameters.')\n",
    "total_trainable_params_u = sum(p.numel() for p in model_u.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params_u:,} training parameters.')\n",
    "#\n",
    "print(f'{total_trainable_params_enc + total_trainable_params_u*2:,} total parameters')\n"
   ],
   "id": "d90641c01216ae5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Problem Instance",
   "id": "3725aadfee077717"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T19:39:32.432041575Z",
     "start_time": "2025-12-13T19:39:32.422131101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "class DarcyFlowContinuous(ProblemInstance):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            device=device,\n",
    "            dtype=dtype\n",
    "        )\n",
    "\n",
    "        self.mollifier = Mollifier()\n",
    "        self.n_grid = int_grid.shape[0]\n",
    "        self.int_grid = int_grid.to(self.device)\n",
    "        self.v = v.to(self.device)\n",
    "        self.dv_dr = dv_dr.to(self.device)\n",
    "        self.model_dict = {\n",
    "            'u': model_u,\n",
    "            'a': model_a,\n",
    "            'enc': model_enc\n",
    "        }\n",
    "\n",
    "    def loss_beta(self, a: torch.Tensor) -> Optional[torch.Tensor]:\n",
    "        return 0\n",
    "\n",
    "    def loss_pde(self, a: torch.Tensor, nc=100) -> torch.Tensor:\n",
    "        n_batch = a.shape[0]\n",
    "        beta = self.model_dict['enc'](a)\n",
    "\n",
    "        ##### Data points\n",
    "        # cx:size(nc,1,2) R:Size(nc,1,1)\n",
    "        xc, R = genPoint.weight_centers(n_center=nc, R_max=1e-4, R_min=1e-4)\n",
    "        xc, R = xc.to(self.device), R.to(self.device)\n",
    "\n",
    "        # size(nc,n_grid,2)\n",
    "        x = self.int_grid * R + xc\n",
    "        #size(nc*n_grid, 2) -> (n_batch, nc*n_grid, 2)\n",
    "        x = x.reshape(-1,2).repeat((n_batch,1,1))\n",
    "        x = Variable(x, requires_grad=True)\n",
    "\n",
    "        ############ Test functions ############\n",
    "        v = self.v.repeat((nc,1,1)).reshape(-1,1)\n",
    "        dv = (self.dv_dr / R).reshape(-1,2)\n",
    "        ############ Model prediction #########\n",
    "        a_detach = fun_a(x.detach(), a)\n",
    "        u = self.model_dict['u'](x, beta)\n",
    "        u = self.mollifier(u, x)\n",
    "\n",
    "        du = grad(inputs=x, outputs=u, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        f = 10. * torch.ones_like(u)\n",
    "        ################ PDE loss ####################\n",
    "        # size(n_batch, nc*n_grid, 2) -> (n_batch, nc, n_grid) -> (n_batch, nc)\n",
    "        left = torch.sum( a_detach*du*dv, dim=-1).reshape(n_batch, nc, self.n_grid)\n",
    "        left = torch.mean(left, dim=-1)\n",
    "        # size(n_batch, nc*n_grid, 1) -> (n_batch, nc, n_grid) -> (n_batch, nc)\n",
    "        right = (f * v).reshape(n_batch, nc, self.n_grid)\n",
    "        right = torch.mean(right, dim=-1)\n",
    "        ################################################\n",
    "        res = (left-right)**2\n",
    "        res, indices = torch.sort(res.flatten(), descending=True, dim=0)\n",
    "        loss_res = torch.sum( res[0:100*10] )\n",
    "\n",
    "        return self.get_loss(left, right) + loss_res\n",
    "\n",
    "\n",
    "    def loss_data(self, x: torch.Tensor, a: torch.Tensor, u: torch.Tensor) -> torch.Tensor:\n",
    "        beta = self.model_dict['enc'](a)\n",
    "        u_pred = self.model_dict['u'](x, beta)\n",
    "        u_pred = self.mollifier(u_pred, x)\n",
    "\n",
    "        return self.get_loss(u_pred, u)\n",
    "\n",
    "    def get_model_dict(self) -> Dict[str, nn.Module]:\n",
    "        return self.model_dict\n",
    "\n",
    "    def error(self, x: torch.Tensor, a: torch.Tensor, u: torch.Tensor) -> torch.Tensor:\n",
    "        beta = self.model_dict['enc'](a)\n",
    "        u_pred = self.model_dict['u'](x, beta)\n",
    "        u_pred = self.mollifier(u_pred, x)\n",
    "\n",
    "        return self.get_loss(u_pred, u)\n"
   ],
   "id": "d020835cbb43b091",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "95594279310ec2ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:59:38.168055914Z",
     "start_time": "2025-12-14T14:59:38.089902419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "solver = Solver(\n",
    "    problem_instance=DarcyFlowContinuous(),\n",
    "    device=device,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "solver.train_mbgd(\n",
    "    a_train=a_train,\n",
    "    u_train=u_train,\n",
    "    x_train=x_train,\n",
    "    a_test=a_test,\n",
    "    u_test=u_test,\n",
    "    x_test=x_test,\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        'AdamW',\n",
    "        lr=5e-4\n",
    "    ),\n",
    "    scheduler_config=SchedulerConfig(\n",
    "        type='StepLR',\n",
    "        step_size=np.int32(2000/5),\n",
    "        gamma=0.5,\n",
    "    ),\n",
    "    loss_weights=LossWeights(\n",
    "        pde=1.0,\n",
    "        data=0.25,\n",
    "        beta=0.0\n",
    "    ),\n",
    "    batch_size=50,\n",
    "    epochs=2000,\n",
    "    epoch_show=50,\n",
    "    custom_run_tag='trial_run'\n",
    ")\n"
   ],
   "id": "d83db2515373b80d",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
