# Training Configuration
# NF architecture is hardcoded per-problem in _build_models()

run_name: "20_just_nf"
device: "cuda"
artifact_root: "runs"
seed: 10086

problem:
  type: "darcy_continuous"
  train_data: "data/darcy_continuous/smh_train/"
  test_data: "data/darcy_continuous/smh_test_in/"

stages:
  - foundation

pretrained:
  path: "./runs/stable_dgno_darcy_continuous/foundation/weights/best_dgno.pt"

# Phase 1: DGNO (encoder + decoders)
dgno:
  epochs: 10000
  batch_size: 50
  epoch_show: 50
  loss_weights:
    pde: 0.25
    data: 2.0
  optimizer:
    type: Adam
    lr: 0.001
    weight_decay: 0.0001
  scheduler:
    type: StepLR
    step_size: 2500
    gamma: 0.5

# Phase 2: NF (normalizing flow on latents)
# Note: NF architecture (dim, num_flows, hidden_dim, num_layers) is
# hardcoded in the problem's _build_models() method
nf:
  epochs: 15000
  batch_size: 64
  epoch_show: 500
  optimizer:
    type: Adam
    lr: 0.0005
    weight_decay: 0.0
  scheduler:
#    type: StepLR
#    step_size: 2501
#    gamma: 0.5
    type: CosineAnnealing
    total_steps: 15000
    eta_min: 0.00001

#    total_steps: 10000
#    pct_start: 0.05
#    anneal_strategy: 'cos'
#    div_factor: 10
#    final_div_factor: 100


# Optional: Encoder training (separate phase)
encoder:
  epochs: 1000
  batch_size: 100
  epoch_show: 100
  freeze_decoder: true
  freeze_nf: true
  loss_weights:
    pde: 0
    data: 0
  optimizer:
    type: Adam
    lr: 0.0001
    weight_decay: 0.0001
  scheduler:
    type: Plateau
    patience: 50
    factor: 0.5

