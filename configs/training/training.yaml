# Training Configuration
# NF architecture is hardcoded per-problem in _build_models()

run_name: "example"
device: "cuda"
artifact_root: "runs"
seed: 10086

problem:
  type: "darcy_continuous"
  train_data: "data/darcy_continuous/smh_train/"

stages:
  - foundation

# pretrained:
#   path: "/path/to/checkpoint.pt"

# Phase 1: DGNO (encoder + decoders)
dgno:
  epochs: 10000
  batch_size: 50
  epoch_show: 50
  loss_weights:
    pde: 0.25
    data: 2.0
  optimizer:
    type: Adam
    lr: 0.001
  scheduler:
    type: StepLR
    step_size: 2500
    gamma: 0.5

# Phase 2: NF (normalizing flow on latents)
# Note: NF architecture (dim, num_flows, hidden_dim, num_layers) is
# hardcoded in the problem's _build_models() method
nf:
  epochs: 10000
  batch_size: 50
  epoch_show: 100
  optimizer:
    type: Adam
    lr: 0.001
  scheduler:
    type: StepLR
    step_size: 2500
    gamma: 0.5

# Optional: Encoder training (separate phase)
encoder:
  epochs: 1000
  batch_size: 100
  epoch_show: 100
  freeze_decoder: true
  freeze_nf: true
  optimizer:
    type: Adam
    lr: 0.0001
  scheduler:
    type: Plateau
    patience: 50
    factor: 0.5

