
run_name: "darcy_continuous"
device: "cuda"
artifact_root: "runs"
seed: 10086

problem:
  type: "darcy_continuous"
  train_data: "data/darcy_continuous/smh_train/"
  test_data: "data/darcy_continuous/smh_test_in/"

#pretrained:
#  path: "./runs/2026-01-22_16-18-13_darcy_continuous/weights/best.pt"

# Joint training configuration (encoder + decoders + NF)
training:
  epochs: 12500
  batch_size: 50
  epoch_show: 200

  # Loss weights for PDE and data terms
  # Note: NF loss doesn't need a weight (gradients don't flow to encoder/decoders)
  loss_weights:
    pde: 0.25
    data: 2.0
  # Latent standardization for NF
  # IMPORTANT: Must match between training and evaluation!
  standardize_latent: false
  optimizer:
    type: Adam
    lr: 0.001
    weight_decay: 0.000001
  scheduler:
    type: StepLR
    step_size: 2500
    gamma: 0.5